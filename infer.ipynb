{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 20:59:35.337154: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, Dropout, GlobalMaxPooling1D, Conv1D, BatchNormalization, MaxPooling1D, Flatten, Input\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import prettytable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from word2vec import *\n",
    "\n",
    "from data_preprocessing import preprocess_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the best model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_classes(model, text_to_predict):\n",
    "    probabilities = model.predict(text_to_predict)\n",
    "    # This will yield a 2D array containing one probability - the probability of the text belonging to class 1\n",
    "    return {'suicide': probabilities[0][0], 'non-suicide': 1 - probabilities[0][0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 785ms/step\n",
      "I love you: {'suicide': 0.18202238, 'non-suicide': 0.8179776221513748}\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "I want to kill myself: {'suicide': 0.8856266, 'non-suicide': 0.11437338590621948}\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "I'm crying tears of joy!: {'suicide': 0.3011573, 'non-suicide': 0.6988427042961121}\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "I don't want to live anymore: {'suicide': 0.949522, 'non-suicide': 0.05047798156738281}\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "I hate ice cream: {'suicide': 0.00279928, 'non-suicide': 0.997200720012188}\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer and the best model\n",
    "with open('Data/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "best_model = tf.keras.models.load_model('Models/CNN_best_model.h5')\n",
    "\n",
    "texts_to_predict = [\n",
    "    'I love you',\n",
    "    'I want to kill myself',\n",
    "    \"I'm crying tears of joy!\",\n",
    "    \"I don't want to live anymore\",\n",
    "    \"I hate ice cream\"\n",
    "]\n",
    "\n",
    "for txt in texts_to_predict:\n",
    "    # Preprocess the text\n",
    "    text_to_predict = preprocess_text(txt)\n",
    "\n",
    "    # Tokenize the text\n",
    "    text_to_predict = tokenizer.texts_to_sequences([txt])\n",
    "\n",
    "    # Pad the sequences\n",
    "    text_to_predict = pad_sequences(text_to_predict, maxlen=100, padding='post')\n",
    "\n",
    "    # Predict the class of the text. print the probability of the text belonging to each class\n",
    "    prediction = predict_classes(best_model, text_to_predict)\n",
    "    print(f'{txt}: {prediction}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
